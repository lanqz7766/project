{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_2018_cleaned = pd.read_csv('../data/processed/crime_2018_cleaned.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(crime_2018_cleaned.drop('Arrest', axis = 1))\n",
    "y = crime_2018_cleaned['Arrest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    214170\n",
      "1     53393\n",
      "Name: Arrest, dtype: int64\n",
      "4.011199970033525\n"
     ]
    }
   ],
   "source": [
    "#How many arrest cases are present in our dataset?\n",
    "print(crime_2018_cleaned['Arrest'].value_counts())\n",
    "print(crime_2018_cleaned['Arrest'].value_counts()[0]/crime_2018_cleaned['Arrest'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_test, y_1, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_tr, X_cv, y_tr, y_cv = train_test_split(X_1, y_1, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qizhenlan/Desktop/CS6010/CSproject/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/qizhenlan/Desktop/CS6010/CSproject/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/qizhenlan/Desktop/CS6010/CSproject/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Calculating for finding Best C\n",
    "roc_tr=[]\n",
    "roc_cv=[]\n",
    "max_auc_score=0\n",
    "C_best=0\n",
    "tuned_parameters =[10**-4, 10**-2, 10**0, 10**2, 10**4]\n",
    "for i in tuned_parameters:\n",
    "    lr=LogisticRegression(C=i, penalty='l1', class_weight= 'balanced')\n",
    "    # fitting the model on train data\n",
    "    lr.fit(X_tr,y_tr)\n",
    "     #predict the response on the crossvalidation \n",
    "    pred_cv = lr.predict_proba(X_cv)\n",
    "    pred_cv=(pred_cv)[:,1]\n",
    "    roc_cv.append(roc_auc_score(y_cv,pred_cv))\n",
    "    \n",
    "     # predict the response on the traininig\n",
    "    pred_tr = lr.predict_proba(X_tr)\n",
    "    pred_tr=(pred_tr)[:,1]\n",
    "    roc_tr.append(roc_auc_score(y_tr,pred_tr))\n",
    "    #finding best c using max value of auc score\n",
    "    if roc_auc_score(y_cv,pred_cv)>max_auc_score:\n",
    "        C_best=i\n",
    "        max_auc_score=roc_auc_score(y_cv,pred_cv)\n",
    "        \n",
    "print(C_best)        \n",
    "print(max_auc_score)\n",
    "C1=C_best\n",
    "auc1=max_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = []\n",
    "Balanced_Acc = []\n",
    "F1 = []\n",
    "auc = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for trainIndex, textIndex in skf.split(X, y):\n",
    "    xTrain, xTest = X[trainIndex], X[textIndex]\n",
    "    yTrain, yTest = y[trainIndex], y[textIndex]\n",
    "    \n",
    "    \n",
    "    # fit an Extra Trees model to the data\n",
    "    #model = ExtraTreesClassifier(n_estimators=20,n_jobs=4)\n",
    "    #model = ExtraTreesClassifier(n_estimators=100) # by default n_estimator/tree is 10\n",
    "    model = ExtraTreesClassifier(n_estimators=50)\n",
    "\n",
    "    #model = ExtraTreesClassifier()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    #model.fit(xTrain, yTrain,xTest,yTest)\n",
    "    #exTreeModel=model.fit(xTrain, yTrain,xTest,yTest)\n",
    "    #exTreeModelAcc=compute_accuracy(model,xTrain, yTrain,xTest,yTest)\n",
    "    \n",
    "    fi.append(model.feature_importances_)\n",
    "    \n",
    "    sfm = SelectFromModel(model, threshold=0.05) # considering the importance greater than 0.05\n",
    "    sfm.fit(xTrain, yTrain)\n",
    "    xTrain = sfm.transform(xTrain)\n",
    "    xTest = sfm.transform(xTest)\n",
    "    clr=LogisticRegression(C=1, penalty='l1', class_weight= 'balanced')\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    yPred = clf.predict(xTest)\n",
    "    Balanced_Acc.append(balanced_accuracy_score(yTest, yPred))\n",
    "    F1.append(f1_score(yTest,yPred))\n",
    "    auc.append(roc_auc_score(yTest, yPred))\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "importance=pd.Series(np.mean(fi,axis=0))\n",
    "selected_features_importance=pd.DataFrame({'Feature' :list(df_feature.columns),'Importance' :importance})\n",
    "print(selected_features_importance.sort_values(by='Importance'))\n",
    "#print(pd.DataFrame(fi).mean(axis = 0))\n",
    "print(\"Balanced Accuracy: \", np.mean(Balanced_Acc))\n",
    "print(\"F1: \", np.mean(F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
